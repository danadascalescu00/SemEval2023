{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mzWFhS8-Z0n",
        "outputId": "1580a52d-693c-456f-b074-1a18f9391964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkh2n_rkYjYR",
        "outputId": "40af3c84-b347-43af-a384-b54a1acc8d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 17.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=ba20df3c6628bde9c7e158da85497bafa0c0563c5734f307fa7e2e043beeb15e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/e3/f2/1de1c2e3ed742e1df73e0f15d58864e50c7e64f607b548d6cf\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 24.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqDFyAYtCy8q",
        "outputId": "1cc7da91-ea59-46a1-abfb-fc9ba0d064c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "from sklearn.svm import SVC\n",
        "import string\n",
        "import unidecode\n",
        "import emoji\n",
        "import nltk\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oWtMNcpEC50B"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/NLP2/data/train_all_tasks.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tcadYX-8DU3B",
        "outputId": "d4fdf97d-6f88-491f-a95c-1a4a96d7b46d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      rewire_id  \\\n",
              "0       sexism2022_english-7358   \n",
              "1       sexism2022_english-2367   \n",
              "2       sexism2022_english-3073   \n",
              "3      sexism2022_english-14895   \n",
              "4       sexism2022_english-4118   \n",
              "...                         ...   \n",
              "13995  sexism2022_english-14185   \n",
              "13996  sexism2022_english-18629   \n",
              "13997   sexism2022_english-3320   \n",
              "13998  sexism2022_english-13309   \n",
              "13999  sexism2022_english-12402   \n",
              "\n",
              "                                                    text label_sexist  \\\n",
              "0                  Damn, this writing was pretty chaotic   not sexist   \n",
              "1      Yeah, and apparently a bunch of misogynistic v...   not sexist   \n",
              "2           How the FUCK is this woman still an MP!!!???   not sexist   \n",
              "3      Understand. Know you're right. At same time I ...   not sexist   \n",
              "4         Surprized they didn't stop and rape some women   not sexist   \n",
              "...                                                  ...          ...   \n",
              "13995  complexes like the 'nice chicks' that go after...       sexist   \n",
              "13996  \"GRAPHIC Germany - Muslim \"refugee\" stabbing h...   not sexist   \n",
              "13997  Lol I imagine there would be simps that are li...   not sexist   \n",
              "13998  It's not, the girls I go on dates with don't k...   not sexist   \n",
              "13999  How can he be an incel? He does have a girlfri...   not sexist   \n",
              "\n",
              "      label_category             label_vector  \n",
              "0               none                     none  \n",
              "1               none                     none  \n",
              "2               none                     none  \n",
              "3               none                     none  \n",
              "4               none                     none  \n",
              "...              ...                      ...  \n",
              "13995  2. derogation  2.1 descriptive attacks  \n",
              "13996           none                     none  \n",
              "13997           none                     none  \n",
              "13998           none                     none  \n",
              "13999           none                     none  \n",
              "\n",
              "[14000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14ee7db0-7d0b-4ca6-a671-f5a2845ff786\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rewire_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label_sexist</th>\n",
              "      <th>label_category</th>\n",
              "      <th>label_vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sexism2022_english-7358</td>\n",
              "      <td>Damn, this writing was pretty chaotic</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sexism2022_english-2367</td>\n",
              "      <td>Yeah, and apparently a bunch of misogynistic v...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sexism2022_english-3073</td>\n",
              "      <td>How the FUCK is this woman still an MP!!!???</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sexism2022_english-14895</td>\n",
              "      <td>Understand. Know you're right. At same time I ...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sexism2022_english-4118</td>\n",
              "      <td>Surprized they didn't stop and rape some women</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13995</th>\n",
              "      <td>sexism2022_english-14185</td>\n",
              "      <td>complexes like the 'nice chicks' that go after...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>2. derogation</td>\n",
              "      <td>2.1 descriptive attacks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13996</th>\n",
              "      <td>sexism2022_english-18629</td>\n",
              "      <td>\"GRAPHIC Germany - Muslim \"refugee\" stabbing h...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13997</th>\n",
              "      <td>sexism2022_english-3320</td>\n",
              "      <td>Lol I imagine there would be simps that are li...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13998</th>\n",
              "      <td>sexism2022_english-13309</td>\n",
              "      <td>It's not, the girls I go on dates with don't k...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13999</th>\n",
              "      <td>sexism2022_english-12402</td>\n",
              "      <td>How can he be an incel? He does have a girlfri...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14ee7db0-7d0b-4ca6-a671-f5a2845ff786')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14ee7db0-7d0b-4ca6-a671-f5a2845ff786 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14ee7db0-7d0b-4ca6-a671-f5a2845ff786');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DA97Grt2Dgga"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub( r\"(\\?+)\", r\" twinterrogation\", text)\n",
        "  text = re.sub( r\"(!+|¡+)\", r\" twexclamation\", text)\n",
        "  text = re.sub( r\"(?<=^|(?<=[^a-zA-Z0-9-\\\\.]))#([A-Za-z]+[A-Za-z0-9]+)\", r\"twhastag\", text)\n",
        "\n",
        "\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "          u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "          u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "          u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "  text = emoji_pattern.sub(r'', text)\n",
        "  text = re.sub('[^a-zA-Z]',\" \",text)\n",
        "\n",
        "  tokenizer = TweetTokenizer()\n",
        "  stop_words_nltk = set(stopwords.words('english'))\n",
        "  stemmer = PorterStemmer() \n",
        "\n",
        "  words = tokenizer.tokenize(text)\n",
        "  filtered_words = [word for word in words if word not in stop_words_nltk]\n",
        "  stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "  return ' '.join(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8JrXt1p6XoO9"
      },
      "outputs": [],
      "source": [
        "data['text'] = data['text'].apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GbH7F1uEdTG3",
        "outputId": "603ad22b-8974-4969-86ae-3c3f52369aa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      rewire_id  \\\n",
              "0       sexism2022_english-7358   \n",
              "1       sexism2022_english-2367   \n",
              "2       sexism2022_english-3073   \n",
              "3      sexism2022_english-14895   \n",
              "4       sexism2022_english-4118   \n",
              "...                         ...   \n",
              "13995  sexism2022_english-14185   \n",
              "13996  sexism2022_english-18629   \n",
              "13997   sexism2022_english-3320   \n",
              "13998  sexism2022_english-13309   \n",
              "13999  sexism2022_english-12402   \n",
              "\n",
              "                                                    text label_sexist  \\\n",
              "0                              damn write pretti chaotic   not sexist   \n",
              "1      yeah appar bunch misogynist virgin one turn ga...   not sexist   \n",
              "2                fuck woman still mp twexclam twinterrog   not sexist   \n",
              "3      understand know right time know enough money w...   not sexist   \n",
              "4                                surpriz stop rape women   not sexist   \n",
              "...                                                  ...          ...   \n",
              "13995  complex like nice chick go bad boy nah nah nah...       sexist   \n",
              "13996  graphic germani muslim refuge stab younger yo ...   not sexist   \n",
              "13997     lol imagin would simp like deserv ugli guy jfl   not sexist   \n",
              "13998  girl go date kiss first date text back first date   not sexist   \n",
              "13999  incel twinterrog girlfriend fuck anyon say kis...   not sexist   \n",
              "\n",
              "      label_category             label_vector  \n",
              "0               none                     none  \n",
              "1               none                     none  \n",
              "2               none                     none  \n",
              "3               none                     none  \n",
              "4               none                     none  \n",
              "...              ...                      ...  \n",
              "13995  2. derogation  2.1 descriptive attacks  \n",
              "13996           none                     none  \n",
              "13997           none                     none  \n",
              "13998           none                     none  \n",
              "13999           none                     none  \n",
              "\n",
              "[14000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bef0449f-79dc-41cd-ba32-9c7eb6956d30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rewire_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label_sexist</th>\n",
              "      <th>label_category</th>\n",
              "      <th>label_vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sexism2022_english-7358</td>\n",
              "      <td>damn write pretti chaotic</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sexism2022_english-2367</td>\n",
              "      <td>yeah appar bunch misogynist virgin one turn ga...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sexism2022_english-3073</td>\n",
              "      <td>fuck woman still mp twexclam twinterrog</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sexism2022_english-14895</td>\n",
              "      <td>understand know right time know enough money w...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sexism2022_english-4118</td>\n",
              "      <td>surpriz stop rape women</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13995</th>\n",
              "      <td>sexism2022_english-14185</td>\n",
              "      <td>complex like nice chick go bad boy nah nah nah...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>2. derogation</td>\n",
              "      <td>2.1 descriptive attacks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13996</th>\n",
              "      <td>sexism2022_english-18629</td>\n",
              "      <td>graphic germani muslim refuge stab younger yo ...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13997</th>\n",
              "      <td>sexism2022_english-3320</td>\n",
              "      <td>lol imagin would simp like deserv ugli guy jfl</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13998</th>\n",
              "      <td>sexism2022_english-13309</td>\n",
              "      <td>girl go date kiss first date text back first date</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13999</th>\n",
              "      <td>sexism2022_english-12402</td>\n",
              "      <td>incel twinterrog girlfriend fuck anyon say kis...</td>\n",
              "      <td>not sexist</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bef0449f-79dc-41cd-ba32-9c7eb6956d30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bef0449f-79dc-41cd-ba32-9c7eb6956d30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bef0449f-79dc-41cd-ba32-9c7eb6956d30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w03RCi3sdvFi"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(data, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c2zM9qheZlF"
      },
      "source": [
        "# Task 1\n",
        "\n",
        "\n",
        "TF IDF + SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-4GIFXueElr",
        "outputId": "ab10a6ac-6ae5-48bf-ef3e-568017cdf9cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels: {'not sexist': 0, 'sexist': 1}\n",
            "Params: TFIDF max features=3000, C=1.0,  Kernel=rbf, Acc: 0.8296428571428571\n",
            "Params: TFIDF max features=3000, C=1.0,  Kernel=linear, Acc: 0.8328571428571429\n",
            "Params: TFIDF max features=3000, C=1.5,  Kernel=rbf, Acc: 0.8296428571428571\n",
            "Params: TFIDF max features=3000, C=1.5,  Kernel=linear, Acc: 0.8314285714285714\n",
            "Params: TFIDF max features=3000, C=2.0,  Kernel=rbf, Acc: 0.8260714285714286\n",
            "Params: TFIDF max features=3000, C=2.0,  Kernel=linear, Acc: 0.8289285714285715\n",
            "Params: TFIDF max features=3000, C=2.5,  Kernel=rbf, Acc: 0.825\n",
            "Params: TFIDF max features=3000, C=2.5,  Kernel=linear, Acc: 0.8225\n",
            "Params: TFIDF max features=3000, C=3.0,  Kernel=rbf, Acc: 0.825\n",
            "Params: TFIDF max features=3000, C=3.0,  Kernel=linear, Acc: 0.8192857142857143\n",
            "Params: TFIDF max features=5000, C=1.0,  Kernel=rbf, Acc: 0.8271428571428572\n",
            "Params: TFIDF max features=5000, C=1.0,  Kernel=linear, Acc: 0.8321428571428572\n"
          ]
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "X_train, y_train = train['text'], train['label_sexist']\n",
        "y_train = le.fit_transform(y_train)\n",
        "print(\"Labels: {}\".format(dict(zip(le.classes_, le.transform(le.classes_)))))\n",
        "\n",
        "X_test, y_test = test['text'], test['label_sexist']\n",
        "y_test = le.fit_transform(y_test)\n",
        "\n",
        "#hyperparameter tuning using TFIDF\n",
        "\n",
        "max_features_tfidf_param = [3000, 5000, 8000]\n",
        "C_param = [1.0, 1.5, 2.0, 2.5, 3.0]\n",
        "kernel_param = ['rbf', 'linear']\n",
        "\n",
        "best_parameters = {}\n",
        "best_parameters['best_acc'] = 0\n",
        "\n",
        "for max_features in max_features_tfidf_param:\n",
        "  #initiate the TfidfVectorizer\n",
        "  tfidf = TfidfVectorizer(max_features=max_features)\n",
        "\n",
        "  #convert the training and validation data to tf-idf indexes\n",
        "  X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
        "  X_test_tfidf = tfidf.transform(X_test).toarray()\n",
        "  \n",
        "  for C in C_param:\n",
        "    for kernel in kernel_param:\n",
        "      model = SVC(C=C, kernel=kernel)\n",
        "      model.fit(X_train_tfidf, y_train)\n",
        "      y_pred = model.predict(X_test_tfidf)\n",
        "      score = accuracy_score(y_pred, y_test)\n",
        "      print('Params: TFIDF max features={}, C={},  Kernel={}, Acc: {}'.format(max_features, C, kernel, score))\n",
        "\n",
        "      #save the parameters for the best score\n",
        "      if score > best_parameters['best_acc']:\n",
        "        best_parameters['best_acc'] = score\n",
        "        best_parameters[\"max_features\"] = max_features\n",
        "        best_parameters[\"C\"] = C\n",
        "        best_parameters['kernel'] = kernel_param\n",
        "\n",
        "\n",
        "print(best_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TIF IDF + LR\n"
      ],
      "metadata": {
        "id": "pOH9flhknvLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "le = LabelEncoder()\n",
        "X_train, y_train = train['text'], train['label_sexist']\n",
        "y_train = le.fit_transform(y_train)\n",
        "print(\"Labels: {}\".format(dict(zip(le.classes_, le.transform(le.classes_)))))\n",
        "\n",
        "X_test, y_test = test['text'], test['label_sexist']\n",
        "y_test = le.fit_transform(y_test)\n",
        "\n",
        "#hyperparameter tuning using TFIDF\n",
        "\n",
        "max_features_tfidf_param = [3000, 5000, 8000]\n",
        "penalty_param = ['l2', 'none']\n",
        "\n",
        "best_parameters = {}\n",
        "best_parameters['best_acc'] = 0\n",
        "\n",
        "for max_features in max_features_tfidf_param:\n",
        "  #initiate the TfidfVectorizer\n",
        "  tfidf = TfidfVectorizer(max_features=max_features)\n",
        "\n",
        "  #convert the training and validation data to tf-idf indexes\n",
        "  X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
        "  X_test_tfidf = tfidf.transform(X_test).toarray()\n",
        "\n",
        "  for penalty in penalty_param:\n",
        "    model = LogisticRegression(penalty=penalty, max_iter = 100)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    score = accuracy_score(y_pred, y_test)\n",
        "    print('Params: TFIDF max features={}, penalty={}, Acc: {}'.format(max_features, penalty, score))\n",
        "\n",
        "    #save the parameters for the best score\n",
        "    if score > best_parameters['best_acc']:\n",
        "      best_parameters['best_acc'] = score\n",
        "      best_parameters[\"max_features\"] = max_features\n",
        "      best_parameters[\"penalty\"] = penalty\n",
        "\n",
        "\n",
        "print(best_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZhmgwDTn3EA",
        "outputId": "c2022006-ac13-497a-99a3-103b2deb8f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: {'not sexist': 0, 'sexist': 1}\n",
            "Params: TFIDF max features=3000, penalty=l2, Acc: 0.8328571428571429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params: TFIDF max features=3000, penalty=none, Acc: 0.7785714285714286\n",
            "Params: TFIDF max features=5000, penalty=l2, Acc: 0.8332142857142857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params: TFIDF max features=5000, penalty=none, Acc: 0.7596428571428572\n",
            "Params: TFIDF max features=8000, penalty=l2, Acc: 0.8325\n",
            "Params: TFIDF max features=8000, penalty=none, Acc: 0.7742857142857142\n",
            "{'best_acc': 0.8332142857142857, 'max_features': 5000, 'penalty': 'l2'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2\n",
        "\n",
        "TFIDF + SVM"
      ],
      "metadata": {
        "id": "AE13w-WUMT0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_task2 = data[data['label_sexist'] == 'sexist']\n",
        "train, test = train_test_split(data_task2, test_size=0.2)"
      ],
      "metadata": {
        "id": "W5-2BBNRMVnY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "X_train, y_train = train['text'], train['label_category']\n",
        "y_train = le.fit_transform(y_train)\n",
        "print(\"Labels: {}\".format(dict(zip(le.classes_, le.transform(le.classes_)))))\n",
        "\n",
        "X_test, y_test = test['text'], test['label_category']\n",
        "y_test = le.fit_transform(y_test)\n",
        "\n",
        "#hyperparameter tuning using TFIDF\n",
        "\n",
        "max_features_tfidf_param = [3000, 5000, 8000]\n",
        "C_param = [1.0, 2.0, 3.0]\n",
        "kernel_param = ['rbf', 'linear']\n",
        "\n",
        "best_parameters = {}\n",
        "best_parameters['best_acc'] = 0\n",
        "\n",
        "for max_features in max_features_tfidf_param:\n",
        "  #initiate the TfidfVectorizer\n",
        "  tfidf = TfidfVectorizer(max_features=max_features)\n",
        "\n",
        "  #convert the training and validation data to tf-idf indexes\n",
        "  X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
        "  X_test_tfidf = tfidf.transform(X_test).toarray()\n",
        "  \n",
        "  for C in C_param:\n",
        "    for kernel in kernel_param:\n",
        "      model = SVC(C=C, kernel=kernel)\n",
        "      model.fit(X_train_tfidf, y_train)\n",
        "      y_pred = model.predict(X_test_tfidf)\n",
        "      score = accuracy_score(y_pred, y_test)\n",
        "      print('Params: TFIDF max features={}, C={},  Kernel={}, Acc: {}'.format(max_features, C, kernel, score))\n",
        "\n",
        "      #save the parameters for the best score\n",
        "      if score > best_parameters['best_acc']:\n",
        "        best_parameters['best_acc'] = score\n",
        "        best_parameters[\"max_features\"] = max_features\n",
        "        best_parameters[\"C\"] = C\n",
        "        best_parameters['kernel'] = kernel_param\n",
        "\n",
        "\n",
        "print(best_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grfgRGyfM_xa",
        "outputId": "6eac4dc1-e453-419b-eefc-99000a6265f2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: {'1. threats, plans to harm and incitement': 0, '2. derogation': 1, '3. animosity': 2, '4. prejudiced discussions': 3}\n",
            "Params: TFIDF max features=3000, C=1.0,  Kernel=rbf, Acc: 0.5088235294117647\n",
            "Params: TFIDF max features=3000, C=1.0,  Kernel=linear, Acc: 0.5029411764705882\n",
            "Params: TFIDF max features=3000, C=2.0,  Kernel=rbf, Acc: 0.4970588235294118\n",
            "Params: TFIDF max features=3000, C=2.0,  Kernel=linear, Acc: 0.48823529411764705\n",
            "Params: TFIDF max features=3000, C=3.0,  Kernel=rbf, Acc: 0.4970588235294118\n",
            "Params: TFIDF max features=3000, C=3.0,  Kernel=linear, Acc: 0.47352941176470587\n",
            "Params: TFIDF max features=5000, C=1.0,  Kernel=rbf, Acc: 0.5073529411764706\n",
            "Params: TFIDF max features=5000, C=1.0,  Kernel=linear, Acc: 0.5117647058823529\n",
            "Params: TFIDF max features=5000, C=2.0,  Kernel=rbf, Acc: 0.5029411764705882\n",
            "Params: TFIDF max features=5000, C=2.0,  Kernel=linear, Acc: 0.48823529411764705\n",
            "Params: TFIDF max features=5000, C=3.0,  Kernel=rbf, Acc: 0.49264705882352944\n",
            "Params: TFIDF max features=5000, C=3.0,  Kernel=linear, Acc: 0.49264705882352944\n",
            "Params: TFIDF max features=8000, C=1.0,  Kernel=rbf, Acc: 0.5102941176470588\n",
            "Params: TFIDF max features=8000, C=1.0,  Kernel=linear, Acc: 0.5029411764705882\n",
            "Params: TFIDF max features=8000, C=2.0,  Kernel=rbf, Acc: 0.5014705882352941\n",
            "Params: TFIDF max features=8000, C=2.0,  Kernel=linear, Acc: 0.48676470588235293\n",
            "Params: TFIDF max features=8000, C=3.0,  Kernel=rbf, Acc: 0.48970588235294116\n",
            "Params: TFIDF max features=8000, C=3.0,  Kernel=linear, Acc: 0.4823529411764706\n",
            "{'best_acc': 0.5117647058823529, 'max_features': 5000, 'C': 1.0, 'kernel': ['rbf', 'linear']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFIDF + LR"
      ],
      "metadata": {
        "id": "OovsjcsjPp2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "le = LabelEncoder()\n",
        "X_train, y_train = train['text'], train['label_category']\n",
        "y_train = le.fit_transform(y_train)\n",
        "print(\"Labels: {}\".format(dict(zip(le.classes_, le.transform(le.classes_)))))\n",
        "\n",
        "X_test, y_test = test['text'], test['label_category']\n",
        "y_test = le.fit_transform(y_test)\n",
        "\n",
        "#hyperparameter tuning using TFIDF\n",
        "\n",
        "max_features_tfidf_param = [3000, 5000, 8000]\n",
        "penalty_param = ['l2', 'none']\n",
        "\n",
        "best_parameters = {}\n",
        "best_parameters['best_acc'] = 0\n",
        "\n",
        "for max_features in max_features_tfidf_param:\n",
        "  #initiate the TfidfVectorizer\n",
        "  tfidf = TfidfVectorizer(max_features=max_features)\n",
        "\n",
        "  #convert the training and validation data to tf-idf indexes\n",
        "  X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
        "  X_test_tfidf = tfidf.transform(X_test).toarray()\n",
        "\n",
        "  for penalty in penalty_param:\n",
        "    model = LogisticRegression(penalty=penalty, max_iter = 100)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    score = accuracy_score(y_pred, y_test)\n",
        "    print('Params: TFIDF max features={}, penalty={}, Acc: {}'.format(max_features, penalty, score))\n",
        "\n",
        "    #save the parameters for the best score\n",
        "    if score > best_parameters['best_acc']:\n",
        "      best_parameters['best_acc'] = score\n",
        "      best_parameters[\"max_features\"] = max_features\n",
        "      best_parameters[\"penalty\"] = penalty\n",
        "\n",
        "\n",
        "print(best_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnpq1MUgPkyT",
        "outputId": "6acfc5dd-a199-400c-ca1b-c83eeb7323f7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: {'1. threats, plans to harm and incitement': 0, '2. derogation': 1, '3. animosity': 2, '4. prejudiced discussions': 3}\n",
            "Params: TFIDF max features=3000, penalty=l2, Acc: 0.5029411764705882\n",
            "Params: TFIDF max features=3000, penalty=none, Acc: 0.4647058823529412\n",
            "Params: TFIDF max features=5000, penalty=l2, Acc: 0.4970588235294118\n",
            "Params: TFIDF max features=5000, penalty=none, Acc: 0.4661764705882353\n",
            "Params: TFIDF max features=8000, penalty=l2, Acc: 0.49117647058823527\n",
            "Params: TFIDF max features=8000, penalty=none, Acc: 0.475\n",
            "{'best_acc': 0.5029411764705882, 'max_features': 3000, 'penalty': 'l2'}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}